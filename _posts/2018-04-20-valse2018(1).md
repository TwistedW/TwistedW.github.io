---
layout: post
title: Valse2018会议记录（1）
category: 技术
tags: [conference]
description: 
---

> 今年的Valse会议在大连召开，我也是有幸和导师一起参加了这次会议。今天是大会召开的第一天，听了一些报告收获蛮多的，眼界涨了些。
晚上也是没事，对白天的内容做一个简短的梳理。

# Tutorial for GAN Part 1#

由于我的研究方向是GAN这一方面，所以我比较关注这次会议GAN的tutorial，学界的大牛去分享自己利用GAN的心得是十分宝贵的学习机会。
今天是Valse会议的第一天，而且Valse会议面向的大部分成员是在校的研究生和博士所以安排了tutorial这个环节。

上午一个上午都在做GAN的tutorial，这次GAN的tutorial是分为两场，第一场是由新加坡国立大学的冯佳时教授带来的GAN的基本原理和注意点，
第二场是由哈尔冰工业大学的左旺孟教授带来的GAN的应用与拓展。两场都十分的精彩，下面我们先来看看第一场报告的精彩点。

**GAN的基本原理**

首先我们介绍一下冯佳时教授，冯老师目前在新加坡国立大学担任助理教授在计算机视觉有很多突出成就，我们一起来看看冯教授的报告要点。

冯教授主要说了GAN的基本原理，深入浅出的带我们将GAN的原理重新梳理了一遍，讲的很耐心细致，具体GAN的原理我也不重复复述了，
如果想详细了解的话，可以看我之前写的GAN的[博客](https://twistedw.github.io/2018/01/29/original-GAN.html)。

冯教授强调了研究生成模型的意义：

- 测试高维复杂的概率分布建模
- 模拟未来（规划，仿真）
- 处理确实数据
- 多模态输出
- 解决真实的数据生成问题

冯教授梳理了一下生成模型：

<p align="center">
    <img src="/assets/img/Conference/2018valse1.png" height = '400px'>
</p>

强调了GAN模型是

- 使用隐编码
- 近似一致（优于变分模型）
- 不需要马尔科夫链
- 生成数据质量高

GAN可以用来做什么：

1.真实数据生成任务

-图像生成

-视频生成

-自然语句生成

-音乐生成

2.解决数据不足问题

-多视角、多任务学习

-半监督学习

3.强化学习

......

在说完GAN的基本原理后，冯老师分享了GAN的一些应用：

1.可用于超分辨率图像的生成（以SRGAN为例）

![](/assets/img/Conference/2018valse2.png)

可以实现的效果为：

![](/assets/img/Conference/2018valse3.png)

2.图像细粒度仿真

![](/assets/img/Conference/2018valse4.gif)

这篇文章中提到了局部对抗损失函数和利用早期生成的精细化图像来优化判别器。

![](/assets/img/Conference/2018valse5.png)

![](/assets/img/Conference/2018valse6.png)

3.金字塔GAN（LAPGAN）

利用多尺度图像生成来一步步优化生成效果

![](/assets/img/Conference/2018valse7.png)

4.可作为视频未来预测

5.冯教授团队利用GAN做了人脸去遮挡（这部分图片后续添加，等待大会PPT公开）

6.冯教授团队利用GAN做了小物体检测

![](/assets/img/Conference/2018valse8.png)

最后，冯教授总结了GAN的特性。

优点：

- 计算梯度时只用到了反向传播，而不需要马尔科夫链

- 训练时不需要对隐变量做推断

- 理论上，只要是可微分函数都能用于构建G和D，因而能够与深度学习结合来学习深度产生式函数（deep generative model）

- 统计角度上来看，G参数更新不是直接来自于数据样本，而是使用来自D的反向梯度

缺点：

- 生成器的分布Pg(G)没有显示的表达

- 比较难训练，D和G在时间上需要很好的同步，例如更新k次G后更新一次D

冯教授也是对比克GAN与其他深度产生式模型所存在的困难：

<p align="center">
    <img src="/assets/img/Conference/2018valse9.png" height = '400px'>
</p>

我感觉最有价值的是冯教授分享了GAN的训练技巧：

1.学习条件概率模型![](/assets/img/Conference/2018valsebase1.png)通常提供比学习P(x)更好的生成样本

2.学习联合概率模型P(x,y)结果也通常更好

3.单边标签平滑

-1->0.9

-有效的正则

-不改变分类准确率（只改变置信度）

-防止判别器模型梯度过大

-防止局限于特定样本

OK！冯佳时教授分享GAN的经验差不多就是这些了，当然我只是粗略的记录，没有具体展开，这些还需要我回去再好好消化。
时间有限今天就写这么多，接下来我还会更新Tutorial for GAN Part 2也就是左旺孟教授对GAN的应用和拓展的讲解，
当然接下来会议期间有好的收获还会继续分享。

谢谢观看，希望对您有所帮助，欢迎指正错误，欢迎一起讨论！！！
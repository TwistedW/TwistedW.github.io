---
layout: post
title: 论文AAE解读
category: 技术
tags: [图像生成，机器学习]
description: 
---

> [Adversarial Autoencoders](https://arxiv.org/abs/1511.05644)将Autoencoder和GAN结合，是一篇很有启发性的文章

GAN和VAE是近年来很火的生成模型（关于GAN和VAE，我之前写过几篇了），对于这两个模型的研究层出不穷，变体无数，而将这两者结合也是一种优秀的思路。
GAN说白了就是对抗，VAE就是一种Autoencoders，而本文的AAE就是将对抗的思想融入到Autoencoders中来。如下图所示：

![](/assets/img/VAE_GAN/AEGAN.png)

这个图大概的意思是：上半部分就是AE，我们都知道AE需要把一个真实分布映射成隐层的z，AAE就是在z这里动手脚，（如图下半部分所示）在此加上对抗思想来优化这个z。

# 优势 #
知道了大概的思路，在具体理解一个事情前，我们先来进行一些思考：

从上图中可以明确地看出，这个模型不像原来的GAN一样生成出一些样本，然后和真实数据比较，梯度反向传播从而渐渐优化模型；这个模型操作的是隐层的z，
通过调整z来达到得到想要的生成的效果。真实样本可以是不连续的（普通GAN无法训练优化），但是z却是连续的，我们可以做到通过微调z来生成更加真实的样本。
也就是说AAE完美避开了GAN无法生成离散样本的问题。

# Adversarial Autoencoders： #

首先来展示一些下文有关的符号：

p(z) 任意的先验分布

q(z) 聚合后验分布

q(z | x) encoding分布

p(x | z) decoding分布

pd(x) 真实数据分布

p(x) 模型分布

paper中给出的q(z)的表达式:

![](/assets/img/VAE_GAN/AE.png)

AAE就是一种让 q(z)去匹配p(z)的AE，配合最上边的符号解释，我们可以理解这句话，也可以理解这个模型。通过图可以看出这是一个AE框架，包括encoder、
中间编码层和decoder。我们让中间编码层的q(z)去匹配一个p(z)，怎么做到呢？此时对抗思想就出场了，见下图：

![](/assets/img/VAE_GAN/Struture.png)

红框中与“AE简易说明图”中的内容类似，就是一个AE，对抗思想的引入在于黄框中的内容，AE的encoder部分，作为GAN中的generator，生成样本，也就
是编码层中的编码，与黄框左边部分的真实样本，一个符合p(z)分布的样本混在一起让discriminator进行辨别，从而使discriminator与作为generator
的encoder部分不断优化，并且在对抗的同时，AE也在最小化reconstruction error，最终可以生成更好的样本。

文中列出了三种q(z | x)的选择，包括确定性函数，高斯后验和通用近似后验，其中使用确定性函数，它的q（z）只是和真实数据分布有关，其他两种的
q（z）除了与真实分布有关，还与这两种方式中的某些随机性有关。不同的选择在训练过程中会有细微的差别，但是文中提到，他们使用不同的方式会得到
类似的结果。

谢谢观看，希望对您有所帮助，欢迎指正错误，欢迎一起讨论！！！